{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6tmtoXNyde-"
      },
      "outputs": [],
      "source": [
        "# Colab 한글 깨짐 해결 위한 폰트 설치\n",
        "!sudo apt-get install -y fonts-nanum\n",
        "!sudo fc-cache -fv\n",
        "!rm ~/.cache/matplotlib -rf\n",
        "\n",
        "# 런타임 재시작 !"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1t8KPTB0GDeN"
      },
      "outputs": [],
      "source": [
        "# matplotlib 설정\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.rc('font', family='NanumBarunGothic')\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "UZaQhBg7GDeZ"
      },
      "source": [
        "# Gradient Boosting"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rA2hOEE_GDeb"
      },
      "source": [
        "- 사이킷런에서 제공하는 GradientBoostingClassifier와 GradientBoostingRegressor모두 DecisionTreeRegressor를 사용하여 구현되어 있다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tsxCeIhMGRDQ"
      },
      "outputs": [],
      "source": [
        "# GradientBoostingClassifier?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TfHfe4cdGDec"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "model_grad = GradientBoostingClassifier()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "cgPvCX0jGDef"
      },
      "source": [
        "#### 그래디언트 부스팅의 파라미터\n",
        "  - loss : 그래디언트 부스팅에 다른 비용 함수를 사용할 수 있다. 기본값은 로지스틱 손실 함수인 'deviance'이고 에이다부스트에서 사용하는 'exponential'도 있다.\n",
        "    - GradientBoostingRegressor에도 loss파라미터가 존재하는데 기본값은 'ls(최소제곱)'이고 'lad(최소 절댓값 오차)', 'huber(후버 손실함수)', 'quantile(사분위수 손실함수)'가 있다.\n",
        "  - learning_rate : 에이다 부스트의 파라미터와 비슷하게 이전 트리의 오차를 얼마나 강하게 보정할 것인지를 정해주는 파라미터이다. 기본값은 0.1이다.\n",
        "  - subsample : 각 트리가 훈련할 때 사용할 데이터의 비율을 지정한다. 'subsample = 0.3'이면 각 트리는 무작위로 선택된 30%의 훈련 데이터로 학습된다.\n",
        "  - 결정 트리를 제어하는 파라미터인 'max_depth, min_samples_leaf' 등을 가지고 있다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GYWpY-sgGDeg"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "cancer = load_breast_cancer()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target,\n",
        "                                                    random_state = 0)\n",
        "\n",
        "model_grad = GradientBoostingClassifier(random_state = 0).fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8ipX4t6GDej",
        "outputId": "e76c9903-dd48-4b2b-ea50-e1e76df87c23"
      },
      "outputs": [],
      "source": [
        "print('train score : {:.3f}'.format(model_grad.score(X_train, y_train)))\n",
        "print('test score : {:.3f}'.format(model_grad.score(X_test, y_test)))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9CfVzLq_GDen"
      },
      "source": [
        "- 훈련 점수가 1.0으로 과적합을 보이고 있다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3sNPG2jGDeo",
        "outputId": "c67cb45b-dc5a-4cdb-a9ea-5034c8de8d1f"
      },
      "outputs": [],
      "source": [
        "model_grad = GradientBoostingClassifier(random_state=0, max_depth=1).fit(X_train, y_train)\n",
        "print('train score : {:.3f}'.format(model_grad.score(X_train, y_train)))\n",
        "print('test score : {:.3f}'.format(model_grad.score(X_test, y_test)))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ABlkKQcvGDer"
      },
      "source": [
        "- 과적합을 막기 위해서 트리의 깊이를 1로 설정했다. 모델의 점수를 확인해보니 훈련 점수는 낮아지고 테스트 점수는 높아진 것을 확인할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75Alep2-GDer",
        "outputId": "0d5b0953-0585-4f94-ad19-0d8488bda58b"
      },
      "outputs": [],
      "source": [
        "model_grad = GradientBoostingClassifier(random_state=0, learning_rate=0.01).fit(X_train, y_train)\n",
        "print('train score : {:.3f}'.format(model_grad.score(X_train, y_train)))\n",
        "print('test score : {:.3f}'.format(model_grad.score(X_test, y_test)))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "IECEKCnQGDeu"
      },
      "source": [
        "- 학습률을 낮춰서도 과적합을 방지할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 830
        },
        "id": "oAxzXjxlGDev",
        "outputId": "e66d9e7e-990a-4e68-8605-5fa7cc3a6688",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "grbc = GradientBoostingClassifier(random_state=0, max_depth=1).fit(X_train, y_train)\n",
        "\n",
        "plt.figure(figsize = (10,10))\n",
        "X = np.arange(cancer.data.shape[1])\n",
        "Y = grbc.feature_importances_\n",
        "plt.barh(X, Y, align='center')\n",
        "plt.yticks(X, cancer.feature_names)\n",
        "plt.ylim(-1, cancer.data.shape[1])\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "DgZWpOxWGDex"
      },
      "source": [
        "- 몇몇 특성들을 완전히 무시하고 있는 것을 확인할 수 있다."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "uJUO_h4iGDey"
      },
      "source": [
        "- 그래디언트 부스팅의 단점은 파라미터를 잘 조정해야 하며 훈련 시간이 다른 모델에 비해 길다.\n",
        "- 그래디언트 부스팅은 n_estimators를 크게하면 모델이 복잡해져 과적합이 될 가능성이 크다. 적절한 n_estimaotrs와 learning_rate를 찾는것이 관건이다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xp6G3WfKGDez"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
